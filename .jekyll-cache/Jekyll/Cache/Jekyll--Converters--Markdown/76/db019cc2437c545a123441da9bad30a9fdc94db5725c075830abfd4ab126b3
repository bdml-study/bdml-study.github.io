I"@<p>이번시간에는 <strong>Sherlock: A Deep Learning Approach to Semantic Data Type Detection</strong> 논문을 리뷰해볼 예정입니다.</p>

<p>이 논문은 테이블 데이터에서 컬럼의 내용만 보고 컬럼의 semantic type을 추출하기 위한 방법을 제시하고 있습니다.</p>

<p>그럼 시작하겠습니다.</p>

<!--more-->

<h2 id="abstract">Abstract</h2>

<p>테이블 형태의 데이터에서 각 컬럼별 semantic type을 올바르게 감지하는것은 데이터 사이언스에서 매우 중요하다.</p>

<p>하지만 기존 데이터 분석 시스템은 semantic type을 감지하기 위해 dictionary lookup, 정규표현식 등에 의존하고 있다.</p>

<p>이 방법들은 더티데이터에 강건하지 않고, 적은 수의 타입만 판별가능하다.</p>

<p>이 논문에서는 sherlock이라는 multi-input deep neural network를 통해 semantic type을 감지한다.</p>

<h2 id="introduction">INTRODUCTION</h2>

<p>데이터 준비 및 분석 시스템은 데이터 컬럼의 타입을 정확하게 감지하는데 많은 영향을 받는다</p>

<p>대부분의 시스템은 atomic type을 감지하지만, semantic type은 (atomic type에 비해)불균형적으로 더 강력하고 필수적이다</p>

<p>semantic type은 column과 실제 개념간의 대응 관계를 설정하여 좀 더 명확하고 자세한(finer-grained) 설명을 제공한다</p>

<p>하지만 대부분 type은 다음 표와 같이 표현하는 방법이 많다 (structual 하지 않다)</p>

<figure class="image-card width-wide caption">
  <img src="/images/seminar02/table1.png" alt="table1" />
  
</figure>

<p>그리고 기존의 정규표현식 매칭 방법과 dictionary lookup과 같은 방식은 단순 유형을 감지하는데 좋지만 복잡한 데이터 유형이나 더티 데이터에 매우 취약하다</p>

<p>특히 데이터 프레임의 헤더명을 참고해서 데이터 타입을 알아내는 Tableau같은 어플리케이션에서 원래 있던 헤더를 제거하면 전혀 type 예측을 하지 못하는 것을 볼 수 있다</p>

<figure class="image-card width-wide caption">
  <img src="/images/seminar02/figure2.png" alt="table1" />
  
</figure>

<p>최근 급부상중인 딥러닝 프레임워크가 대규모 코퍼스 학습에 매우 뛰어난 것에 영감을 받아 sherlock을 만들었다</p>

<p>일단 <code class="highlighter-rouge">T2Dv2 Gold Standard</code>에 따라서, DBpedia의 속성을 WebTable corpus와 일치시키는 78개의 semantic type을 고려했다</p>

<p><code class="highlighter-rouge">VizNet corpus</code>를 통해 686,765개의 실제 데이터 컬럼을 추출했다</p>

<p>이 논문에서 각 column은 column value들이 column header에 매칭되는 것으로 간주한다</p>

<p>1,588개의 특성을 추출하고 다양한 통계적, 의미론적 특성들을 설명한다</p>

<p>그리고 column header를 semantic type의 label로 간주하여 semantic type 감지 문제를 multi class classification 문제로 바꿨다</p>

<blockquote>
  <p>본 논문의 주제는 데이터 분석가들을 위해 컬럼의 데이터를 보고 미리 의미있는 타입을 지정해서 카테고리화 하겠다 입니다.
이 논문에서 주장하는 문제가 정확히 일치하는 테스크도 많겠지만 저는 이 논문에서 tabula data에서 컬럼별 특징을 추출하는 방법에 대해 조금 더 관심이 갔습니다.</p>
</blockquote>

<h2 id="data">DATA</h2>

<p>대규모 저장소에서 column 및 feature를 추출하는 방법에 대한 설명</p>

<h3 id="data-collection">Data Collection</h3>

<p>onolotgy 기반 <code class="highlighter-rouge">WordNet</code>과 <code class="highlighter-rouge">DBpedia</code>를 합쳐서 275개의 semantic type을 추출해낼 것이다</p>

<p>결과적으로 275개의 type과 일치하는 6,146,940개의 column이 생성되었고 column header를 semantic type의 정답과 일치시키면 더 좋은 training data를 만들 수 있다</p>

<h3 id="feature-extraction">Feature Extraction</h3>

<p>각 column은 가변 길이를 가졌고 엄청나게 다양하게 해석될 수 있기 때문에 신경망에 들어갈 Input으로 변환하기 위해 특징을 추출해야 한다</p>

<p>global statistics 27개, aggregated character distribution 960개, pretrained word embedding 200개, self-trained paragraph vector 400개를 추출한다</p>

<h4 id="global-statistics">global statistics</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>high level의 통계적 특성을 추출한다 (column 엔트로피 등)

범주형 데이터 및 수치형 자료를 구분하도록 다음 27개의 feature를 추출한다

&lt;figure class="image-card width-wide caption"&gt;   &lt;img src="/images/seminar02/figure8.png" alt="table1" /&gt;
</code></pre></div></div>

<p>&lt;/figure&gt;</p>

<h4 id="character-level-distributions">character-level distributions</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>각 문자들의 분포를 설명하는 통계적 수치를 대표하는 feature를 추출한다

ascii의 96개 문자를 통해 10개씩 각 문자별로 통계치를 뽑아서 총 960개의 feature를 생성한다

any, all, mean, max 를 비롯해 ‘-’의 포함 여부, ‘/’의 갯수 평균 등등의 feature가 있다

wordembeddings
    - 특정 semantic type은 특정 단어가 빈번하게 나올 수 있다
    - 이러한 특징을 추출하기 위해 word embedding을 사용했다
    - Glove를 사용했고 없는 단어는 생략, 여러 단어가 나오면 각 단어의 임베딩 값의 평균을 사용한다
    - 그리고 column의 모든 값에 대한 임베딩 값의 평균, 최빈값, 중앙값 및 분산을 활용한다

paragraph vectors
    - 각각의 column을 고정 길이의 벡터로 표현하기 위해 `PV-DBOW`를 변형해서 사용했다
</code></pre></div></div>

<h3 id="filtering-and-preprocessing">Filtering and Preprocessing</h3>

<p>다음 그림에서 보듯이 type 마다 VizNet corpus에서 나타나는 빈도가 다르므로 최대 15000개 까지, 1000개 미만은 제외했다</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;figure class="image-card width-wide caption"&gt;   &lt;img src="/images/seminar02/figure3.png" alt="table1" /&gt;
</code></pre></div></div>

<p>&lt;/figure&gt;</p>
:ET